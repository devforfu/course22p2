{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f926346",
   "metadata": {},
   "source": [
    "# Attempting a minimal diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2986f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, torch, torchvision, torch.nn.functional as F, torchvision.transforms.functional as TF, matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import partial\n",
    "from torch import tensor,nn,optim\n",
    "from torch.utils.data import DataLoader,default_collate\n",
    "from torchvision.utils import make_grid\n",
    "from datasets import load_dataset,load_dataset_builder\n",
    "from miniai.datasets import *\n",
    "from miniai.learner import *\n",
    "from fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8273fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray_r'\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5992dfd1",
   "metadata": {},
   "source": [
    "Load a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99edd708",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = 'image','label'\n",
    "name = \"fashion_mnist\"\n",
    "dsd = load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c14d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi(b): b[x] = [TF.to_tensor(o) for o in b[x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee14c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1024\n",
    "tds = dsd.with_transform(transformi)\n",
    "dls = DataLoaders.from_dd(tds, bs)\n",
    "dt = dls.train\n",
    "xb,yb = next(iter(dt))\n",
    "xb.shape,yb[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c9ad1",
   "metadata": {},
   "source": [
    "Define a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2460571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(inc, outc): return nn.Conv2d(inc, outc, kernel_size=5, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0d9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicUNet(nn.Module):\n",
    "    \"A minimal UNet implementation.\"\n",
    "    def __init__(self, inc, outc):\n",
    "        super().__init__()\n",
    "        self.down_layers = torch.nn.ModuleList([conv2d(inc, 32), conv2d(32, 64), conv2d(64, 64)])\n",
    "        self.up_layers = torch.nn.ModuleList([conv2d(64, 64), conv2d(64, 32), conv2d(32, outc)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = []\n",
    "        for i, l in enumerate(self.down_layers):\n",
    "            x = F.silu(l(x))\n",
    "            h.append(x)\n",
    "            if i < 2: x = F.max_pool2d(x, 2)\n",
    "        for i, l in enumerate(self.up_layers):\n",
    "            if i > 0: x = F.interpolate(x, scale_factor=2)\n",
    "            x += h.pop()\n",
    "            x = l(x)\n",
    "            if i<len(self.up_layers)-1: x = F.silu(x)\n",
    "        return (x.sigmoid()*2)-0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cfb358",
   "metadata": {},
   "source": [
    "Define the corruption:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt(x, amount):\n",
    "    \"Corrupt the input `x` by mixing it with noise according to `amount`\"\n",
    "    noise = torch.rand_like(x)\n",
    "    amount = amount.view(-1, 1, 1, 1) # Sort shape so broadcasting works\n",
    "    return x*(1-amount) + noise*amount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f9f08",
   "metadata": {},
   "source": [
    "Logging callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b48e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogLossesCB(Callback):\n",
    "    def __init__(self): self.losses = []\n",
    "    def after_batch(self): self.losses.append(self.learn.loss.item())\n",
    "    def after_fit(self): plt.plot(self.losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22810d0d",
   "metadata": {},
   "source": [
    "I chose to write a new training callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2449fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainCB(TrainCB):\n",
    "    def predict(self):\n",
    "        bs = self.learn.batch[0].shape[0]\n",
    "        noise_amount = torch.rand(bs).to(self.learn.batch[0].device) # Chose random corruption amount\n",
    "        noisy_images = corrupt(self.learn.batch[0], noise_amount) # Noisy images as net inputs\n",
    "        self.learn.preds = self.learn.model(noisy_images)\n",
    "    def get_loss(self):\n",
    "        self.learn.loss = self.learn.loss_func(self.learn.preds, self.learn.batch[0]) # Clean images as targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicUNet(1, 1)\n",
    "cbs = [MyTrainCB(), CudaCB(), ProgressCB(), LogLossesCB()]\n",
    "learn = Learner(model, dls, nn.MSELoss(), lr=2e-3, cbs=cbs, opt_func=optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ff4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67272d79",
   "metadata": {},
   "source": [
    "Viewing the predictions on images with increasing noise levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931891cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some noisy data\n",
    "xb = xb[:8].cpu()\n",
    "amount = torch.linspace(0, 1, xb.shape[0]) # Left to right -> more corruption\n",
    "noised_x = corrupt(xb, amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): preds = model(noised_x.cuda()).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803bc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_grid(ax, tens, title=None):\n",
    "    if title: ax.set_title(title)\n",
    "    ax.imshow(make_grid(tens.cpu())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(11, 6))\n",
    "show_grid(axs[0], xb, 'Input data')\n",
    "show_grid(axs[1], noised_x, 'Corrupted data')\n",
    "show_grid(axs[2], preds, 'Network Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e14161",
   "metadata": {},
   "source": [
    "A very basic sampling method (not ideal), just taking 5 or 10 equal-sized steps towards the models prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one: just break the process into 5 or 10 steps and move 1/10'th of the way there each time:\n",
    "device = 'cuda'\n",
    "n_steps = 5\n",
    "xb = torch.rand(8, 1, 28, 28).to(device) # Start from random\n",
    "step_history = [xb.detach().cpu()]\n",
    "pred_output_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_steps):\n",
    "    with torch.no_grad(): pred = model(xb) # Predict the denoised x0\n",
    "    pred_output_history.append(pred.detach().cpu()) # Store model output for plotting\n",
    "    mix_factor = 1/(n_steps - i) # How much we move towards the prediction\n",
    "    xb = xb*(1-mix_factor) + pred*mix_factor # Move part of the way there\n",
    "    if i < n_steps-1: step_history.append(xb.detach().cpu()) # Store step for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a3dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(n_steps, 2, figsize=(15, n_steps), sharex=True)\n",
    "for i in range(n_steps):\n",
    "    axs[i, 0].imshow(make_grid(step_history[i])[0]),\n",
    "    axs[i, 1].imshow(make_grid(pred_output_history[i])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b94475",
   "metadata": {},
   "source": [
    "# Class Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196e759",
   "metadata": {},
   "source": [
    "Giving the model the labels as conditioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feccb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassConditionedUNet(nn.Module):\n",
    "    \"Wraps a BasicUNet but adds several input channels for class conditioning\"\n",
    "    def __init__(self, in_channels, out_channels, num_classes=10, class_emb_channels=4):\n",
    "        super().__init__()\n",
    "        self.class_emb = nn.Embedding(num_classes, class_emb_channels)\n",
    "        self.net = BasicUNet(in_channels+class_emb_channels, out_channels) # input channels = in_channels+1+class_emb_channels\n",
    "\n",
    "    def forward(self, x, class_labels):\n",
    "        n,c,w,h = x.shape\n",
    "        class_cond = self.class_emb(class_labels) # Map to embedding dinemsion\n",
    "        class_cond = class_cond.view(n, class_cond.shape[1], 1, 1).expand(n, class_cond.shape[1], w, h) # Reshape\n",
    "        \n",
    "        # Net input is now x, noise amound and class cond concatenated together\n",
    "        net_input = torch.cat((x, class_cond), 1)\n",
    "        return self.net(net_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a67ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainCB(TrainCB):\n",
    "    def predict(self):\n",
    "        bs = self.learn.batch[0].shape[0]\n",
    "        noise_amount = torch.rand(bs).to(self.learn.batch[0].device)\n",
    "        noisy_images = corrupt(self.learn.batch[0], noise_amount)\n",
    "        self.learn.preds = self.learn.model(noisy_images, self.learn.batch[1]) # << Labels as conditioning\n",
    "    def get_loss(self): self.learn.loss = self.learn.loss_func(self.learn.preds, self.learn.batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac6cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassConditionedUNet(1, 1)\n",
    "cbs = [MyTrainCB(), CudaCB(), ProgressCB(), LogLossesCB()]\n",
    "learn = Learner(model, dls, nn.MSELoss(), lr=1e-3, cbs=cbs, opt_func=optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ddfce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9acbd53",
   "metadata": {},
   "source": [
    "Sampling as before over 20 steps, but this time with the labels as conditioning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10\n",
    "xb = torch.rand(80, 1, 28, 28).cuda()\n",
    "yb = torch.tensor([[i]*8 for i in range(10)]).flatten().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1877aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_steps):\n",
    "    noise_amount = torch.ones((xb.shape[0], )).to(device) * (1-(i/n_steps))\n",
    "    with torch.no_grad():\n",
    "        pred = model(xb, yb)\n",
    "    mix_factor = 1/(n_steps - i)\n",
    "    xb = xb*(1-mix_factor) + pred*mix_factor\n",
    "    \n",
    "    # Optional: Add a bit of extra noise back at early steps\n",
    "#     if i < 10: xb = corrupt(xb, torch.ones((xb.shape[0], )).to(device)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "ax.imshow(make_grid(xb.detach().cpu().clip(0, 1), nrow=8)[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb12679",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "ax.imshow(make_grid(xb.detach().cpu().clip(0, 1), nrow=8)[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc54fc",
   "metadata": {},
   "source": [
    "You can try fashion_mnist as the dataset without making any changes. This seems to work (suprisingly given the lack of fiddling with training and architecture). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f989bf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
